{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoelS\\AppData\\Local\\Temp\\ipykernel_15828\\1069871969.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  crashes = pd.read_csv('mvc_crashes.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRASH DATE' 'CRASH TIME' 'BOROUGH' 'ZIP CODE' 'LATITUDE' 'LONGITUDE'\n",
      " 'LOCATION' 'ON STREET NAME' 'CROSS STREET NAME' 'OFF STREET NAME'\n",
      " 'NUMBER OF PERSONS INJURED' 'NUMBER OF PERSONS KILLED'\n",
      " 'NUMBER OF PEDESTRIANS INJURED' 'NUMBER OF PEDESTRIANS KILLED'\n",
      " 'NUMBER OF CYCLIST INJURED' 'NUMBER OF CYCLIST KILLED'\n",
      " 'NUMBER OF MOTORIST INJURED' 'NUMBER OF MOTORIST KILLED'\n",
      " 'CONTRIBUTING FACTOR VEHICLE 1' 'CONTRIBUTING FACTOR VEHICLE 2'\n",
      " 'CONTRIBUTING FACTOR VEHICLE 3' 'CONTRIBUTING FACTOR VEHICLE 4'\n",
      " 'CONTRIBUTING FACTOR VEHICLE 5' 'COLLISION_ID' 'VEHICLE TYPE CODE 1'\n",
      " 'VEHICLE TYPE CODE 2' 'VEHICLE TYPE CODE 3' 'VEHICLE TYPE CODE 4'\n",
      " 'VEHICLE TYPE CODE 5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "crashes = pd.read_csv('mvc_crashes.csv')\n",
    "print(crashes.columns.values)\n",
    "\n",
    "cleaned_crashes = crashes[['COLLISION_ID','CRASH DATE','CRASH TIME','BOROUGH','ZIP CODE','LATITUDE','LONGITUDE','NUMBER OF PERSONS INJURED']].copy()\n",
    "cleaned_crashes.rename(columns={\"COLLISION_ID\": \"CollisionID\",\n",
    "\t\t\t\t\t\t\t\t\"CRASH DATE\": \"CrashDate\",\n",
    "\t\t\t\t\t\t\t\t\"CRASH TIME\": \"CrashTime\",\n",
    "\t\t\t\t\t\t\t\t\"BOROUGH\": \"Borough\",\n",
    "\t\t\t\t\t\t\t\t\"ZIP CODE\": \"ZipCode\",\n",
    "\t\t\t\t\t\t\t\t\"LATITUDE\": \"Latitude\",\n",
    "\t\t\t\t\t\t\t\t\"LONGITUDE\": \"Longitude\",\n",
    "\t\t\t\t\t\t\t\t\"NUMBER OF PERSONS INJURED\": \"NumberOfInjured\"\n",
    "\t\t\t\t\t\t\t\t}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CollisionID  NumberOfInjured\n",
      "0            4455765              2.0\n",
      "1            4513547              1.0\n",
      "2            4541903              0.0\n",
      "3            4456314              0.0\n",
      "4            4486609              0.0\n",
      "...              ...              ...\n",
      "2021788      4648110              0.0\n",
      "2021789      4648117              1.0\n",
      "2021790      4648366              0.0\n",
      "2021791      4648129              1.0\n",
      "2021792      4647913              0.0\n",
      "\n",
      "[2021793 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "crashes_only = cleaned_crashes[['CollisionID','CrashDate','NumberOfInjured']].copy()\n",
    "\n",
    "# Adds WeatherID to Crashes\n",
    "#\n",
    "# crashes_only['CrashDate'] = pd.to_datetime(crashes_only['CrashDate'], format='%m/%d/%Y')\n",
    "# epoch = datetime(1970, 1, 1)\n",
    "# for index, row in crashes_only.iterrows():\n",
    "# \tdelta = (row['CrashDate'] - epoch)\n",
    "# \tcrashes_only.loc[index, 'WeatherID'] = delta.days\n",
    "# crashes_only['WeatherID'] = crashes_only['WeatherID'].astype(int)\n",
    "\n",
    "crashes_only.drop(columns=['CrashDate'], inplace=True)\n",
    "print(crashes_only)\n",
    "\n",
    "crashes_only.to_csv('Crashes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location\n",
    "\n",
    "Planänderung: Datenbankentwurf wie im Diagramm dargestellt, mit hinzugefügten Fremdschlüsseln in `Neigbourhoods` und `ZipCodes`. Die `ZipCodeID` entfällt, da der `ZipCode` bereits eindeutig ist. Die Fremdschlüssel `BoroughID` und `NeigbourhoodID` entfallen demach in der `Location` Tabelle. Die `ZipCodeID` entfällt/wird direkt durch den `ZipCode` ersetzt. Des weiteren wird die `LocationID` durch die `CollisionID` ersetzt (zwischen `Location` und `Crashes` besteht eine 1:1 Beziehung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CollisionID  ZipCode   Latitude  Longitude\n",
      "0            4455765        0        NaN        NaN\n",
      "1            4513547        0        NaN        NaN\n",
      "2            4541903        0        NaN        NaN\n",
      "3            4456314    11208  40.667202 -73.866500\n",
      "4            4486609    11233  40.683304 -73.917274\n",
      "...              ...      ...        ...        ...\n",
      "2021788      4648110        0  40.866806 -73.931010\n",
      "2021789      4648117    10457  40.844177 -73.902920\n",
      "2021790      4648366    10006  40.711033 -74.014540\n",
      "2021791      4648129    11433  40.691580 -73.793190\n",
      "2021792      4647913    11433  40.700240 -73.792854\n",
      "\n",
      "[2021793 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "location = cleaned_crashes[['CollisionID','ZipCode','Latitude','Longitude']].copy()\n",
    "location[['ZipCode']] = location[['ZipCode']].fillna(0)\n",
    "location[['ZipCode']] = location[['ZipCode']].replace('     ', 0)\n",
    "location['ZipCode'] = location['ZipCode'].astype(int)\n",
    "print(location)\n",
    "location.to_csv('Location.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "Time hat aktuell ebenfalls `CollisionID` statt `TimeID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = cleaned_crashes[['CollisionID','CrashDate','CrashTime']].copy()\n",
    "time['CrashDateTime'] = pd.to_datetime(time['CrashDate'] + time['CrashTime'], format='%m/%d/%Y%H:%M')\n",
    "print(\"Number of unique days: \" + str(time['CrashDate'].nunique()))\n",
    "print(\"Earliest date: \" + str(time[\"CrashDateTime\"].min()))\n",
    "print(\"Latest date: \" + str(time[\"CrashDateTime\"].max()))\n",
    "\n",
    "# Achtung, Berechnung der WeatherID dauert mehrere Minuten (da for-each)\n",
    "time['CrashDate'] = pd.to_datetime(time['CrashDate'], format='%m/%d/%Y')\n",
    "epoch = datetime(1970, 1, 1)\n",
    "for index, row in crashes_only.iterrows():\n",
    "\tdelta = (row['CrashDate'] - epoch)\n",
    "\ttime.loc[index, 'WeatherID'] = delta.days\n",
    "time['WeatherID'] = time['WeatherID'].astype(int)\n",
    "\n",
    "\n",
    "time.drop(columns=['CrashDate', 'CrashTime'], inplace=True)\n",
    "print(time)\n",
    "\n",
    "time.to_csv('Time.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather\n",
    "\n",
    "Es gab zwischen dem 01.07.2012 und dem 08.09.2023 an 4087 Tagen Unfälle (sind wahrscheinlich alle Tage in dem Zeitraum). Wetterinformationen sind aktuell einmal pro Tag vorhanden (nicht stündlich).\n",
    "\n",
    "`WeatherID` wird berechnet über die Anzahl der Tage seit dem 01.01.1970.\n",
    "\n",
    "Inhalt der CSV:\n",
    "- mittlere Tagestemperatur in °C\n",
    "- Sunrise/Sunset nach ISO 8601\n",
    "- Summe der Regenmenge in mm\n",
    "- Summe der Schneehöhe in cm\n",
    "- maximale Windgeschwindigkeit in km/h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "weather = pd.read_csv(\"open-meteo-edit.csv\")\n",
    "weather['time'] = pd.to_datetime(weather['time'])\n",
    "epoch = datetime(1970, 1, 1)\n",
    "for index, row in weather.iterrows():\n",
    "\tdelta = (row['time'] - epoch)\n",
    "\tweather.loc[index, 'WeatherID'] = delta.days\n",
    "weather['WeatherID'] = weather['WeatherID'].astype(int)\n",
    "\n",
    "weather.drop(columns=['time'], inplace=True)\n",
    "weather.rename(columns={\"temperature_mean\": \"Temperature\",\n",
    "\t\t\t\t\t\t\"sunrise\": \"Sunrise\",\n",
    "\t\t\t\t\t\t\"sunset\": \"Sunset\",\n",
    "\t\t\t\t\t\t\"rain_sum\": \"Rainfall\",\n",
    "\t\t\t\t\t\t\"snowfall_sum\": \"Snowfall\",\n",
    "\t\t\t\t\t\t\"windspeed_max\": \"Windspeed\"\n",
    "\t\t\t\t\t\t}, inplace=True)\n",
    "print(weather)\n",
    "weather.to_csv(\"Weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vehicles = pd.read_csv('mvc_vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_vehicles = vehicles[['UNIQUE_ID','COLLISION_ID','VEHICLE_ID','VEHICLE_TYPE','VEHICLE_YEAR','VEHICLE_MAKE','VEHICLE_MODEL']].copy()\n",
    "cleaned_vehicles.rename(columns={\"UNIQUE_ID\": \"UniqueID\",\n",
    "\t\t\t\t\t\t\t\t\"COLLISION_ID\": \"CollisionID\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_ID\": \"VehicleID\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_TYPE\": \"VehicleType\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_YEAR\": \"VehicleYear\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_MAKE\": \"VehicleMake\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_MODEL\": \"VehicleModel\"\n",
    "\t\t\t\t\t\t\t\t}, inplace=True)\n",
    "cleaned_vehicles.to_csv('cleaned_vehicles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "persons = pd.read_csv('mvc_persons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_persons = persons[['UNIQUE_ID', 'PERSON_ID','COLLISION_ID','VEHICLE_ID','PERSON_AGE','PERSON_INJURY','EMOTIONAL_STATUS','PERSON_SEX','PED_ROLE']].copy()\n",
    "cleaned_persons.rename(columns={\"UNIQUE_ID\": \"UniqueID\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_ID\": \"PersonID\",\n",
    "\t\t\t\t\t\t\t\t\"COLLISION_ID\": \"CollisionID\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_ID\": \"VehicleID\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_AGE\": \"Age\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_INJURY\": \"Injury\",\n",
    "\t\t\t\t\t\t\t\t\"EMOTIONAL_STATUS\": \"EmotionalStatus\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_SEX\": \"Gender\",\n",
    "\t\t\t\t\t\t\t\t\"PED_ROLE\": \"PedRole\"\n",
    "\t\t\t\t\t\t\t\t}, inplace=True)\n",
    "cleaned_persons.to_csv('cleaned_person.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
