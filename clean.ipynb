{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "crashes = pd.read_csv('mvc_crashes.csv')\n",
    "print(crashes.columns.values)\n",
    "\n",
    "cleaned_crashes = crashes[['COLLISION_ID','CRASH DATE','CRASH TIME','BOROUGH','ZIP CODE','LATITUDE','LONGITUDE','NUMBER OF PERSONS INJURED']].copy()\n",
    "cleaned_crashes.rename(columns={\"COLLISION_ID\": \"CollisionID\",\n",
    "\t\t\t\t\t\t\t\t\"CRASH DATE\": \"CrashDate\",\n",
    "\t\t\t\t\t\t\t\t\"CRASH TIME\": \"CrashTime\",\n",
    "\t\t\t\t\t\t\t\t\"BOROUGH\": \"Borough\",\n",
    "\t\t\t\t\t\t\t\t\"ZIP CODE\": \"ZipCode\",\n",
    "\t\t\t\t\t\t\t\t\"LATITUDE\": \"Latitude\",\n",
    "\t\t\t\t\t\t\t\t\"LONGITUDE\": \"Longitude\",\n",
    "\t\t\t\t\t\t\t\t\"NUMBER OF PERSONS INJURED\": \"NumberOfInjured\"\n",
    "\t\t\t\t\t\t\t\t}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_only = cleaned_crashes[['CollisionID','CrashDate','NumberOfInjured']].copy()\n",
    "\n",
    "# Adds WeatherID to Crashes\n",
    "#\n",
    "# crashes_only['CrashDate'] = pd.to_datetime(crashes_only['CrashDate'], format='%m/%d/%Y')\n",
    "# epoch = datetime(1970, 1, 1)\n",
    "# for index, row in crashes_only.iterrows():\n",
    "# \tdelta = (row['CrashDate'] - epoch)\n",
    "# \tcrashes_only.loc[index, 'WeatherID'] = delta.days\n",
    "# crashes_only['WeatherID'] = crashes_only['WeatherID'].astype(int)\n",
    "\n",
    "crashes_only.drop(columns=['CrashDate'], inplace=True)\n",
    "crashes_only[\"NumberOfInjured\"] = crashes_only[\"NumberOfInjured\"].fillna(0)\n",
    "crashes_only[\"NumberOfInjured\"] = crashes_only[\"NumberOfInjured\"].astype(int)\n",
    "print(crashes_only)\n",
    "\n",
    "crashes_only.to_csv('Crashes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location\n",
    "\n",
    "Planänderung: Datenbankentwurf wie im Diagramm dargestellt, mit hinzugefügten Fremdschlüsseln in `Neigbourhoods` und `ZipCodes`. Die `ZipCodeID` entfällt, da der `ZipCode` bereits eindeutig ist. Die Fremdschlüssel `BoroughID` und `NeigbourhoodID` entfallen demach in der `Location` Tabelle. Die `ZipCodeID` entfällt/wird direkt durch den `ZipCode` ersetzt. Des weiteren wird die `LocationID` durch die `CollisionID` ersetzt (zwischen `Location` und `Crashes` besteht eine 1:1 Beziehung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = cleaned_crashes[['CollisionID','ZipCode','Latitude','Longitude']].copy()\n",
    "location[['ZipCode']] = location[['ZipCode']].fillna(0)\n",
    "location[['ZipCode']] = location[['ZipCode']].replace('     ', 0)\n",
    "location['ZipCode'] = location['ZipCode'].astype(int)\n",
    "print(location)\n",
    "location.to_csv('Location.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "Time hat aktuell ebenfalls `CollisionID` statt `TimeID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = cleaned_crashes[['CollisionID','CrashDate','CrashTime']].copy()\n",
    "time['CrashDateTime'] = pd.to_datetime(time['CrashDate'] + time['CrashTime'], format='%m/%d/%Y%H:%M')\n",
    "print(\"Number of unique days: \" + str(time['CrashDate'].nunique()))\n",
    "print(\"Earliest date: \" + str(time[\"CrashDateTime\"].min()))\n",
    "print(\"Latest date: \" + str(time[\"CrashDateTime\"].max()))\n",
    "\n",
    "# Achtung, Berechnung der WeatherID dauert mehrere Minuten (da for-each)\n",
    "time['CrashDate'] = pd.to_datetime(time['CrashDate'], format='%m/%d/%Y')\n",
    "epoch = datetime(1970, 1, 1)\n",
    "for index, row in crashes_only.iterrows():\n",
    "\tdelta = (row['CrashDate'] - epoch)\n",
    "\ttime.loc[index, 'WeatherID'] = delta.days\n",
    "time['WeatherID'] = time['WeatherID'].astype(int)\n",
    "\n",
    "\n",
    "time.drop(columns=['CrashDate', 'CrashTime'], inplace=True)\n",
    "print(time)\n",
    "\n",
    "time.to_csv('Time.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather\n",
    "\n",
    "Es gab zwischen dem 01.07.2012 und dem 08.09.2023 an 4087 Tagen Unfälle (sind wahrscheinlich alle Tage in dem Zeitraum). Wetterinformationen sind aktuell einmal pro Tag vorhanden (nicht stündlich).\n",
    "\n",
    "`WeatherID` wird berechnet über die Anzahl der Tage seit dem 01.01.1970.\n",
    "\n",
    "Inhalt der CSV:\n",
    "- mittlere Tagestemperatur in °C\n",
    "- Sunrise/Sunset nach ISO 8601\n",
    "- Summe der Regenmenge in mm\n",
    "- Summe der Schneehöhe in cm\n",
    "- maximale Windgeschwindigkeit in km/h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Temperature           Sunrise            Sunset  Rainfall  Snowfall  \\\n",
      "0            27.4  2012-07-01T05:28  2012-07-01T20:30       1.7       0.0   \n",
      "1            25.7  2012-07-02T05:29  2012-07-02T20:30       0.0       0.0   \n",
      "2            25.8  2012-07-03T05:30  2012-07-03T20:30       0.0       0.0   \n",
      "3            26.8  2012-07-04T05:30  2012-07-04T20:30       3.9       0.0   \n",
      "4            28.9  2012-07-05T05:31  2012-07-05T20:30       0.0       0.0   \n",
      "...           ...               ...               ...       ...       ...   \n",
      "4084         27.9  2023-09-06T06:27  2023-09-06T19:20       0.0       0.0   \n",
      "4085         27.6  2023-09-07T06:28  2023-09-07T19:19       0.5       0.0   \n",
      "4086         26.0  2023-09-08T06:29  2023-09-08T19:17       7.9       0.0   \n",
      "4087         23.9  2023-09-09T06:30  2023-09-09T19:15      13.7       0.0   \n",
      "4088         22.5  2023-09-10T06:31  2023-09-10T19:14       8.8       0.0   \n",
      "\n",
      "      Windspeed  WeatherID  \n",
      "0          17.0      15522  \n",
      "1          14.0      15523  \n",
      "2          12.1      15524  \n",
      "3          10.9      15525  \n",
      "4          14.4      15526  \n",
      "...         ...        ...  \n",
      "4084        9.2      19606  \n",
      "4085       13.0      19607  \n",
      "4086       13.0      19608  \n",
      "4087       10.9      19609  \n",
      "4088        8.4      19610  \n",
      "\n",
      "[4089 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "weather = pd.read_csv(\"open-meteo-edit.csv\")\n",
    "weather['time'] = pd.to_datetime(weather['time'])\n",
    "epoch = datetime(1970, 1, 1)\n",
    "for index, row in weather.iterrows():\n",
    "\tdelta = (row['time'] - epoch)\n",
    "\tweather.loc[index, 'WeatherID'] = delta.days\n",
    "weather['WeatherID'] = weather['WeatherID'].astype(int)\n",
    "\n",
    "weather.drop(columns=['time'], inplace=True)\n",
    "weather.rename(columns={\"temperature_mean\": \"Temperature\",\n",
    "\t\t\t\t\t\t\"sunrise\": \"Sunrise\",\n",
    "\t\t\t\t\t\t\"sunset\": \"Sunset\",\n",
    "\t\t\t\t\t\t\"rain_sum\": \"Rainfall\",\n",
    "\t\t\t\t\t\t\"snowfall_sum\": \"Snowfall\",\n",
    "\t\t\t\t\t\t\"windspeed_max\": \"Windspeed\"\n",
    "\t\t\t\t\t\t}, inplace=True)\n",
    "print(weather)\n",
    "weather.to_csv(\"Weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature                30.8\n",
      "Sunrise        2023-09-10T06:31\n",
      "Sunset         2023-09-10T19:14\n",
      "Rainfall                  102.0\n",
      "Snowfall                  30.73\n",
      "Windspeed                  60.6\n",
      "WeatherID                 19610\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(weather.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tizian\\AppData\\Local\\Temp\\ipykernel_8532\\4111609607.py:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vehicles = pd.read_csv('mvc_vehicles.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vehicles = pd.read_csv('mvc_vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_vehicles = vehicles[['UNIQUE_ID','COLLISION_ID','VEHICLE_ID','VEHICLE_TYPE','VEHICLE_YEAR','VEHICLE_MAKE','VEHICLE_MODEL']].copy()\n",
    "cleaned_vehicles.rename(columns={\"UNIQUE_ID\": \"UniqueID\",\n",
    "\t\t\t\t\t\t\t\t\"COLLISION_ID\": \"CollisionID\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_ID\": \"VehicleID\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_TYPE\": \"VehicleType\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_YEAR\": \"VehicleYear\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_MAKE\": \"VehicleMake\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_MODEL\": \"VehicleModel\"\n",
    "\t\t\t\t\t\t\t\t}, inplace=True)\n",
    "cleaned_vehicles['VehicleYear'] = cleaned_vehicles['VehicleYear'].fillna(0)\n",
    "cleaned_vehicles['VehicleYear'] = cleaned_vehicles['VehicleYear'].astype(int)\n",
    "\n",
    "cleaned_vehicles.to_csv('Vehicles.csv', index=False)\n",
    "\n",
    "helper = cleaned_vehicles[['UniqueID', 'CollisionID']].copy()\n",
    "helper.to_csv(\"Crashes_Vehicles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "persons = pd.read_csv('mvc_persons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_persons = persons[['UNIQUE_ID', 'PERSON_ID','COLLISION_ID','VEHICLE_ID','PERSON_AGE','PERSON_INJURY','EMOTIONAL_STATUS','PERSON_SEX','PED_ROLE']].copy()\n",
    "cleaned_persons.rename(columns={\"UNIQUE_ID\": \"UniqueID\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_ID\": \"PersonID\",\n",
    "\t\t\t\t\t\t\t\t\"COLLISION_ID\": \"CollisionID\",\n",
    "\t\t\t\t\t\t\t\t\"VEHICLE_ID\": \"VehicleID\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_AGE\": \"Age\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_INJURY\": \"Injury\",\n",
    "\t\t\t\t\t\t\t\t\"EMOTIONAL_STATUS\": \"EmotionalStatus\",\n",
    "\t\t\t\t\t\t\t\t\"PERSON_SEX\": \"Gender\",\n",
    "\t\t\t\t\t\t\t\t\"PED_ROLE\": \"PedRole\"\n",
    "\t\t\t\t\t\t\t\t}, inplace=True)\n",
    "cleaned_persons['Age'] = cleaned_persons['Age'].fillna(0)\n",
    "cleaned_persons['Age'] = cleaned_persons['Age'].astype(int)\n",
    "cleaned_persons.to_csv('cleaned_person.csv', index=False)\n",
    "\n",
    "person_helper = cleaned_persons[['UniqueID', 'CollisionID']].copy()\n",
    "person_helper.to_csv(\"Crashes_Persons.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
